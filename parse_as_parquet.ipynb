{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "import json \n",
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_s3_trigger(trigger_event): \n",
    "    logging.info('Reading s3 event trigger')\n",
    "    s3_event = json.loads(open(f'{trigger_event}', 'r').read())\n",
    "    \n",
    "    s3_key = s3_event.get(\"Records\")[0].get('s3').get('object').get('key')\n",
    "    s3_bucket = s3_event.get(\"Records\")[0].get('s3').get('bucket').get('name')\n",
    "\n",
    "    return s3_bucket, s3_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "bucket = 'ntonthat-apple-health-data'\n",
    "key = urllib.parse.unquote_plus(\"syncs/2023-02-01T06%3A45%3A05.339463.json\", encoding=\"utf-8\")\n",
    "personal = boto3.Session(profile_name='personal')\n",
    "s3 = personal.client(\"s3\")\n",
    "json_data = s3.get_object(Bucket=bucket, Key=key)['Body'].read().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = 'source/syncs/2023-01-26T06:11:46.119648.json'\n",
    "json_data = open(json_file, 'r').read()\n",
    "source_data = []\n",
    "\n",
    "for line in json_data.splitlines():\n",
    "    source_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import tempfile \n",
    "\n",
    "logging.info(\"Converting to dataframe\")\n",
    "df = pd.DataFrame.from_records(source_data)\n",
    "\n",
    "# force conversion types\n",
    "df[\"qty\"] = df[\"qty\"].astype(str)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date.astype(str)\n",
    "\n",
    "logging.info(\"Converting to parquet\")\n",
    "\n",
    "# write to parquet\n",
    "file_name = key.split(\"/\")[-1].split(\".\")[0]\n",
    "parquet_file_name = f\"{file_name}.parquet\"\n",
    "# with io.StringIO() as parquet_buffer:\n",
    "#     df.to_parquet(parquet_buffer, engine=\"fastparquet\")\n",
    "\n",
    "with tempfile.NamedTemporaryFile() as tmp:\n",
    "    df.to_parquet(tmp.name, compression='gzip', engine='fastparquet')\n",
    "    with open(tmp.name, 'rb') as fh:\n",
    "        parquet_buffer = io.BytesIO(fh.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'ntonthat-apple-health-data'\n",
    "\n",
    "response = s3.put_object(\n",
    "        Bucket=bucket,\n",
    "        Key=f\"parquets/{parquet_file_name}\",\n",
    "        Body=parquet_buffer.getvalue(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parquets(event): \n",
    "    s3 = boto3.resource('s3')\n",
    "    personal = boto3.Session(profile_name='personal')\n",
    "    s3 = personal.resource('s3')\n",
    "    bucket, key = read_s3_trigger(event)\n",
    "\n",
    "    # convert contents to native python string\n",
    "    json_data = load_json_from_s3(bucket, key)\n",
    "    \n",
    "    source_data = []\n",
    "    \n",
    "    for line in json_data.splitlines(): \n",
    "        source_data.append(json.loads(line))\n",
    "        \n",
    "    logging.info('Converting to dataframe')\n",
    "    df = pd.DataFrame.from_records(source_data)\n",
    "    \n",
    "    # force conversion types\n",
    "    df['qty'] = df['qty'].astype(str)\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "    \n",
    "    logging.info('Converting to parquet')\n",
    "    \n",
    "    # write to parquet\n",
    "    file_name = key.split('/')[-1].split('.')[0]\n",
    "    parquet_file_name = f'outputs/parquets/{file_name}.parquet'\n",
    "    df.to_parquet(f'{parquet_file_name}')\n",
    "    \n",
    "    s3.meta.client.upload_file(f'{parquet_file_name}', bucket, f'parquets/{parquet_file_name}')\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>qty</th>\n",
       "      <th>name</th>\n",
       "      <th>units</th>\n",
       "      <th>date_updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>957.4229999999992</td>\n",
       "      <td>active_energy</td>\n",
       "      <td>kcal</td>\n",
       "      <td>2023-01-18 09:39:59.454617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>507.22899999999953</td>\n",
       "      <td>active_energy</td>\n",
       "      <td>kcal</td>\n",
       "      <td>2023-01-18 09:39:59.454625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>667.1689999999936</td>\n",
       "      <td>active_energy</td>\n",
       "      <td>kcal</td>\n",
       "      <td>2023-01-18 09:39:59.454626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>667.2439999999998</td>\n",
       "      <td>active_energy</td>\n",
       "      <td>kcal</td>\n",
       "      <td>2023-01-18 09:39:59.454627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>854.7099999999991</td>\n",
       "      <td>active_energy</td>\n",
       "      <td>kcal</td>\n",
       "      <td>2023-01-18 09:39:59.454628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>4.277019999999999</td>\n",
       "      <td>zinc</td>\n",
       "      <td>mg</td>\n",
       "      <td>2023-01-18 09:39:59.479184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>3.40875185</td>\n",
       "      <td>zinc</td>\n",
       "      <td>mg</td>\n",
       "      <td>2023-01-18 09:39:59.479185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>4.005757775</td>\n",
       "      <td>zinc</td>\n",
       "      <td>mg</td>\n",
       "      <td>2023-01-18 09:39:59.479186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>2.8978000000000006</td>\n",
       "      <td>zinc</td>\n",
       "      <td>mg</td>\n",
       "      <td>2023-01-18 09:39:59.479187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>2.10433185</td>\n",
       "      <td>zinc</td>\n",
       "      <td>mg</td>\n",
       "      <td>2023-01-18 09:39:59.479190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>461 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     source        date                 qty           name units  \\\n",
       "0       NaN  2023-01-12   957.4229999999992  active_energy  kcal   \n",
       "1       NaN  2023-01-13  507.22899999999953  active_energy  kcal   \n",
       "2       NaN  2023-01-14   667.1689999999936  active_energy  kcal   \n",
       "3       NaN  2023-01-15   667.2439999999998  active_energy  kcal   \n",
       "4       NaN  2023-01-16   854.7099999999991  active_energy  kcal   \n",
       "..      ...         ...                 ...            ...   ...   \n",
       "456     NaN  2023-01-14   4.277019999999999           zinc    mg   \n",
       "457     NaN  2023-01-15          3.40875185           zinc    mg   \n",
       "458     NaN  2023-01-16         4.005757775           zinc    mg   \n",
       "459     NaN  2023-01-17  2.8978000000000006           zinc    mg   \n",
       "460     NaN  2023-01-18          2.10433185           zinc    mg   \n",
       "\n",
       "                   date_updated  \n",
       "0    2023-01-18 09:39:59.454617  \n",
       "1    2023-01-18 09:39:59.454625  \n",
       "2    2023-01-18 09:39:59.454626  \n",
       "3    2023-01-18 09:39:59.454627  \n",
       "4    2023-01-18 09:39:59.454628  \n",
       "..                          ...  \n",
       "456  2023-01-18 09:39:59.479184  \n",
       "457  2023-01-18 09:39:59.479185  \n",
       "458  2023-01-18 09:39:59.479186  \n",
       "459  2023-01-18 09:39:59.479187  \n",
       "460  2023-01-18 09:39:59.479190  \n",
       "\n",
       "[461 rows x 6 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_parquets(event='source/s3-trigger-event.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groupapps-data-etl31-3.9.16-spark-3-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bdc3cdccd85f8ff01a9ca852d6668b9133087ec76a834e47d45e3b483a224f90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
